{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3swoRe-8XUH",
        "outputId": "675eaae4-13f8-47ac-a12e-2e2b1feacad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "from transformers import TFBertForSequenceClassification\n",
        "from transformers import BertTokenizerFast\n",
        "import tensorflow as tf\n",
        "\n",
        "loaded_tokenizer = BertTokenizerFast.from_pretrained('Tolerblanc/klue-bert-finetuned')\n",
        "loaded_model = TFBertForSequenceClassification.from_pretrained('Tolerblanc/klue-bert-finetuned', output_attentions=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvOaCS-3YMGl",
        "outputId": "07c6451f-1011-49c8-f7a9-0e7d39d45280"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at Tolerblanc/klue-bert-finetuned were not used when initializing TFBertForSequenceClassification: ['dropout_113']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at Tolerblanc/klue-bert-finetuned.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_classifier = TextClassificationPipeline(\n",
        "    tokenizer=loaded_tokenizer,\n",
        "    model=loaded_model,\n",
        "    framework='tf',\n",
        "    return_all_scores=True,\n",
        "    device=0\n",
        ")"
      ],
      "metadata": {
        "id": "3lbceru_1C5V"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **마스킹하는 함수**"
      ],
      "metadata": {
        "id": "A1MemmiD8eJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hate_expression(text_classifier, tokenizer, model,text):\n",
        "  output = text_classifier(text)[0]\n",
        "  clean = output[0]['score']\n",
        "  curse = output[1]['score']\n",
        "  print(f'{text} 가 입력되었으며,')\n",
        "\n",
        "  #모델이 혐오표현이 없다고 판단한 경우\n",
        "  if clean > curse:\n",
        "    print(f'모델은 이 문장을 {clean * 100}% 확률로 깨끗한 문장이라고 추론했습니다.')\n",
        "    return text\n",
        "  #모델이 혐오표현이 있다고 판단한 경우\n",
        "  else:\n",
        "    print(f'모델은 이 문장을 {curse * 100}% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.')\n",
        "\n",
        "    #문장을 단어단위로 분류\n",
        "    words = text.split()\n",
        "    masked_words = []\n",
        "\n",
        "    for word in words:\n",
        "        #wordpice토큰화를 진행하고, 텍스트를 정수 배열 변환\n",
        "        inputs = tokenizer.encode_plus(word, return_tensors=\"tf\")\n",
        "\n",
        "        #하나의 문장만 사용해서 [0]으로 표현\n",
        "        outputs = model(inputs)[0]\n",
        "\n",
        "        #정규화시키고,  일반 표현과 혐오표현에 대한 각각의 확률값을 배열로 표현\n",
        "        probabilities = tf.nn.softmax(outputs, axis=-1)\n",
        "\n",
        "        #혐오표현과 일반표현의 확률이 너무 낮은 경우 임계값 설정\n",
        "        threshold = 0.07514262\n",
        "        if probabilities.numpy()[0, 1] > threshold:\n",
        "          label_predictions = 1\n",
        "        else:\n",
        "          #확률값이 높은 부분의 위치를 숫자로 표현(일반표현 0, 혐오표현 1)\n",
        "          label_predictions = tf.argmax(probabilities, axis=1).numpy()[0]\n",
        "\n",
        "        # 0: 일반, 1: 혐오\n",
        "        if label_predictions ==1:\n",
        "            masked_word = \"*\" * len(word)\n",
        "            masked_words.append(masked_word)\n",
        "        else:\n",
        "            masked_words.append(word)\n",
        "\n",
        "    masked_text = \" \".join(masked_words)\n",
        "    return masked_text"
      ],
      "metadata": {
        "id": "2Nkxx36j1rmV"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**혐오표현 마스킹이 제대로 적용된 경우**"
      ],
      "metadata": {
        "id": "QJOyJNSckwu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text='시바견은 너무 귀엽다'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(\"마스킹:\"+ masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a53tI_7euxZl",
        "outputId": "29ef2c1b-ad94-4a5d-f225-a698c848601f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "시바견은 너무 귀엽다 가 입력되었으며,\n",
            "모델은 이 문장을 99.96039271354675% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "마스킹:시바견은 너무 귀엽다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='새끼 고양이는 귀엽다'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(\"마스킹:\"+ masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1P8SR9XvfNi",
        "outputId": "2246c180-7a90-4df3-e0d1-bb02967c5d82"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "새끼 고양이는 귀엽다 가 입력되었으며,\n",
            "모델은 이 문장을 99.96371269226074% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "마스킹:새끼 고양이는 귀엽다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='아저씨 발냄새 나요'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "id": "i_nkTfN1r6jF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd832e09-fbe4-46e9-eda0-cd41edf53dde"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아저씨 발냄새 나요 가 입력되었으며,\n",
            "모델은 이 문장을 90.98570346832275% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "아저씨 발냄새 나요\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='만두 몇개 시키고 올게'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH1YsMER1rSm",
        "outputId": "8487c001-e419-4cb2-d9ff-1de17e4a4f61"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "만두 몇개 시키고 올게 가 입력되었으며,\n",
            "모델은 이 문장을 99.66683983802795% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "만두 몇개 시키고 올게\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='내가 세금 안내면 너 같은 동사무소에서 프린트나 하는 새끼는 월급 못받고 굶어 뒈져야 돼 병신새끼야.'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEb4z7MC4jsO",
        "outputId": "b19458f3-401e-4c7d-a0ad-2e60998982d8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "내가 세금 안내면 너 같은 동사무소에서 프린트나 하는 새끼는 월급 못받고 굶어 뒈져야 돼 병신새끼야. 가 입력되었으며,\n",
            "모델은 이 문장을 99.95182752609253% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "내가 세금 안내면 너 같은 동사무소에서 프린트나 하는 *** 월급 못받고 굶어 *** 돼 ******\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='이게 돈이면 다 되는 대한민국 클라쓰쥐~~~~~!!!!!'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDKKcBnKnJpM",
        "outputId": "ca2a62a4-04af-4aa7-a469-18952a888f0d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이게 돈이면 다 되는 대한민국 클라쓰쥐~~~~~!!!!! 가 입력되었으며,\n",
            "모델은 이 문장을 55.15960454940796% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "이게 돈이면 다 되는 대한민국 클라쓰쥐~~~~~!!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '저게 시대적언어면 한남충도 시대적언어 아니노 ㅋㅋ\t'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56AizbBCS_u9",
        "outputId": "70cc0e2d-3f7b-441f-ecc2-6916ef1e4cb3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "저게 시대적언어면 한남충도 시대적언어 아니노 ㅋㅋ\t 가 입력되었으며,\n",
            "모델은 이 문장을 99.55450296401978% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "저게 시대적언어면 **** 시대적언어 아니노 ㅋㅋ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'ㅅㅂ'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccEBmREClADV",
        "outputId": "3704f1b5-8309-4aa4-8943-dddc2c1bff64"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ㅅㅂ 가 입력되었으며,\n",
            "모델은 이 문장을 88.87845277786255% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '마 씨발련 아 몇평이고 맷개드갔노'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-mdGjLflDcp",
        "outputId": "e6c75da0-4671-4b1e-ec67-e0aa7fd4efd5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "마 씨발련 아 몇평이고 맷개드갔노 가 입력되었으며,\n",
            "모델은 이 문장을 99.95473027229309% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "마 *** 아 몇평이고 맷개드갔노\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='무게치는거에 인생버린새끼들'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59ECIIQIyOJy",
        "outputId": "29a2dc1a-4600-46b5-c2b4-85576f19e3b1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "무게치는거에 인생버린새끼들 가 입력되었으며,\n",
            "모델은 이 문장을 99.88462924957275% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "무게치는거에 *******\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='이 ㅂㅅ은 그냥 꼼처논돈으로 잘 살아도 뭐라안하는데 눈에 안뛰였으면 버러지같은새키'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm_BoAg6XgZv",
        "outputId": "0acbd13e-58c7-4d6f-d470-a2735ab02432"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이 ㅂㅅ은 그냥 꼼처논돈으로 잘 살아도 뭐라안하는데 눈에 안뛰였으면 버러지같은새키 가 입력되었으며,\n",
            "모델은 이 문장을 99.95831847190857% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "이 *** 그냥 꼼처논돈으로 잘 살아도 뭐라안하는데 눈에 안뛰였으면 *******\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='나라 생긴지 몇 년 됐다고 저런 전통도 있었냐 ㅋㅋ ㅂㄹㅈ ㅋㅋㅋ'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBN7hGnUbka0",
        "outputId": "40aed0bf-499a-458a-9451-ab63e7678511"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나라 생긴지 몇 년 됐다고 저런 전통도 있었냐 ㅋㅋ ㅂㄹㅈ ㅋㅋㅋ 가 입력되었으며,\n",
            "모델은 이 문장을 88.39884996414185% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "나라 *** 몇 * 됐다고 저런 전통도 있었냐 ㅋㅋ *** ㅋㅋㅋ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='니넨얼마나잘살아왔냐ㅋㅋ 열등감오지네'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdE-Hr6Ge6Q6",
        "outputId": "00c2355f-3ef5-4c54-f88e-5e97a751dd8d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "니넨얼마나잘살아왔냐ㅋㅋ 열등감오지네 가 입력되었으며,\n",
            "모델은 이 문장을 97.36399054527283% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "니넨얼마나잘살아왔냐ㅋㅋ ******\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='이ㅂㅅ은 그냥 꼼처논돈으로 잘 살아도 뭐라안하는데 눈에 안뛰였으면 버러지같은새키'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKH_3IpTjcrV",
        "outputId": "8661fe2b-8eab-409d-a20d-8e725810788f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이ㅂㅅ은 그냥 꼼처논돈으로 잘 살아도 뭐라안하는데 눈에 안뛰였으면 버러지같은새키 가 입력되었으며,\n",
            "모델은 이 문장을 99.95836615562439% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "**** 그냥 꼼처논돈으로 잘 살아도 뭐라안하는데 눈에 안뛰였으면 *******\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='^^ㅣ발 우리 미드 뭐야'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(\"마스킹:\"+ masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFZC6vL7v81s",
        "outputId": "a8d5c911-4388-4cc2-8508-cabacc28e421"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^^ㅣ발 우리 미드 뭐야 가 입력되었으며,\n",
            "모델은 이 문장을 97.97800183296204% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "마스킹:**** 우리 미드 뭐야\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='이새키보소'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqGWUFXXmCeJ",
        "outputId": "da5c5013-f335-4f9d-f8cf-7ed7f6005a52"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이새키보소 가 입력되었으며,\n",
            "모델은 이 문장을 99.84443783760071% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "*****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '배고픈데 앞에서 만두 먹네 개시키'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWvDtJNsT5zW",
        "outputId": "88be0155-5b90-4bb8-f635-56846a1ebdc6"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "배고픈데 앞에서 만두 먹네 개시키 가 입력되었으며,\n",
            "모델은 이 문장을 99.68923926353455% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "배고픈데 앞에서 만두 먹네 ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='요목조목 다 따져봐도 특출나게 잘난것도 없는 난쟁이놈이 전생에 나라라도 구했는지 ㅋㅋ 천운을 탔구나...  계속 깝치는 모습보니 안경벗기고 스크류 드라이버로 눈쑤셔버리고 싶다.'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi3uWMfsm9wK",
        "outputId": "84a5c7e5-0b58-4b2c-c166-d5546fd0d518"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "요목조목 다 따져봐도 특출나게 잘난것도 없는 난쟁이놈이 전생에 나라라도 구했는지 ㅋㅋ 천운을 탔구나...  계속 깝치는 모습보니 안경벗기고 스크류 드라이버로 눈쑤셔버리고 싶다. 가 입력되었으며,\n",
            "모델은 이 문장을 99.92628693580627% 확률로 욕설이나 혐오표현이 있는 문장이라고 추론했습니다.\n",
            "요목조목 다 따져봐도 특출나게 잘난것도 없는 ***** 전생에 **** 구했는지 ㅋㅋ 천운을 탔구나... 계속 *** 모습보니 안경벗기고 스크류 드라이버로 ****** 싶다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **혐오표현 마스킹이 제대로 적용되지 않은 경우**"
      ],
      "metadata": {
        "id": "IETywz0qqgF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '바보'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiwkOeOoeZy-",
        "outputId": "5de2475d-0d3b-4733-aa01-e5d7b8062f88"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "바보 가 입력되었으며,\n",
            "모델은 이 문장을 99.91893172264099% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "바보\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='버러지들'\n",
        "masked_text = hate_expression(text_classifier, loaded_tokenizer , loaded_model, text)\n",
        "print(masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvmjhTqryebU",
        "outputId": "35bafc12-ea1b-42ae-b816-03339ef344f7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "버러지들 가 입력되었으며,\n",
            "모델은 이 문장을 79.22764420509338% 확률로 깨끗한 문장이라고 추론했습니다.\n",
            "버러지들\n"
          ]
        }
      ]
    }
  ]
}