{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lime\n",
    "import tensorflow as tf\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from transformers import BertTokenizerFast, TFBertForSequenceClassification, TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load finetuned models from hugging face\n",
    "tokenizer = BertTokenizerFast.from_pretrained('Tolerblanc/klue-bert-finetuned', from_tf=True)\n",
    "model = TFBertForSequenceClassification.from_pretrained('Tolerblanc/klue-bert-finetuned', output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at curse_detection/klue-bert-base were not used when initializing TFBertForSequenceClassification: ['dropout_113']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at curse_detection/klue-bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load finetuned models from local\n",
    "tokenizer = BertTokenizerFast.from_pretrained('curse_detection/klue-bert-base', from_tf=True)\n",
    "model = TFBertForSequenceClassification.from_pretrained('curse_detection/klue-bert-base', output_attentions=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking Functions with LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['clean','curse']\n",
    "\n",
    "def predictor(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"tf\", padding=True)\n",
    "    outputs = model(inputs)\n",
    "    probas = tf.nn.softmax(outputs.logits).numpy()\n",
    "    return probas\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "def lime_masking(lime_explainer, prob_method, texts):\n",
    "\texp = lime_explainer.explain_instance(texts, prob_method)\n",
    "\tfeature_scores = exp.as_list()\n",
    "\tmasked = \"*\" * len(feature_scores[0][0])\n",
    "\ttexts = texts.replace(feature_scores[0][0], masked)\n",
    "\tfor feature, score in feature_scores:\n",
    "\t\tprint(feature, score)\n",
    "\t\tif score > 0.37:\n",
    "\t\t\tmasked = \"*\" * len(feature)\n",
    "\t\t\ttexts = texts.replace(feature, masked)\n",
    "\t\n",
    "\treturn (texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper Function to get clean result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "klue_bert_classifier = TextClassificationPipeline(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model, \n",
    "    framework='tf',\n",
    ")\n",
    "\n",
    "def get_result(classifier, masking_method, explainer, prob_method, text):\n",
    "\toutput = classifier(text)[0]\n",
    "\tif output['label'] == 'LABEL_1':\n",
    "\t\ttext = masking_method(explainer, prob_method, text)\n",
    "\treturn (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'내 앞에서 만두 ** ***'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(klue_bert_classifier, lime_masking, explainer, predictor, \"내 앞에서 만두 먹네 개시키\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "씨발련 0.3035191844508606\n",
      "대하이햄하고 0.13552007294222623\n",
      "해밨나 0.12440237129615614\n",
      "니 0.09173280537749583\n",
      "몇평이고 0.06997125798159522\n",
      "맷개드갔노 -0.025232380037995952\n",
      "마 0.025212365564952707\n",
      "아 -0.019426309057547272\n",
      "마 *** 아 몇평이고 맷개드갔노 니 대하이햄하고 해밨나\n",
      "\n",
      "씨발련아 0.2610076683030981\n",
      "대하이햄하고 0.1560522748491922\n",
      "해밨나 0.12329999754743852\n",
      "니 0.07214382352365727\n",
      "몇평이고 0.055339407872269986\n",
      "마 0.02281098961764866\n",
      "맷개드갔노 0.010028274612021285\n",
      "마 **** 몇평이고 맷개드갔노 니 대하이햄하고 해밨나\n"
     ]
    }
   ],
   "source": [
    "print(get_result(klue_bert_classifier, lime_masking, explainer, predictor, \"마 씨발련 아 몇평이고 맷개드갔노 니 대하이햄하고 해밨나\"))\n",
    "print()\n",
    "print(get_result(klue_bert_classifier, lime_masking, explainer, predictor, \"마 씨발련아 몇평이고 맷개드갔노 니 대하이햄하고 해밨나\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나라 생긴지 몇 년이나 됐다고 저런 전통도 있었냐 ㅋㅋ *** ㅋㅋㅋ'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(klue_bert_classifier, lime_masking, explainer, predictor, \"나라 생긴지 몇 년이나 됐다고 저런 전통도 있었냐 ㅋㅋ ㅂㄹㅈ ㅋㅋㅋ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'내가 세금 안내면 너 같은 동사무소에서 프린트나 하는 새끼는 월급 못받고 굶어 뒈져야 돼 *****.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(klue_bert_classifier, lime_masking, explainer, predictor, \\\n",
    "\t\"내가 세금 안내면 너 같은 동사무소에서 프린트나 하는 새끼는 월급 못받고 굶어 뒈져야 돼 병신새끼야.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오마쥬가 뭔진 앎?'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(klue_bert_classifier, lime_masking, explainer, predictor, \\\n",
    "\t\"오마쥬가 뭔진 앎?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'지랄 났다 진짜 ** 대체 종강은 언제하냐?'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(klue_bert_classifier, lime_masking, explainer, predictor, \\\n",
    "\t\"지랄 났다 진짜 시발 대체 종강은 언제하냐?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "씨벌련아 0.08935724090607579\n",
      "씨벌련이 0.0858298729359353\n",
      "토씨하나 0.07181015790380983\n",
      "조져버리네 0.04700403646018927\n",
      "좆중복 0.030699808498733255\n",
      "로 -0.005387206049654063\n",
      "그대 0.004605442312728676\n",
      "아침에 0.003470220259322148\n",
      "안바꾸고 0.0031380933723337864\n",
      "올린거 0.00228072761986878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'씨벌련이 닉변하고 아침에 올린거 토씨하나 안바꾸고  그대-로 좆중복 조져버리네 ****'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(klue_bert_classifier, lime_masking, explainer, predictor, \\\n",
    "\t\"씨벌련이 닉변하고 아침에 올린거 토씨하나 안바꾸고  그대-로 좆중복 조져버리네 씨벌련아\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
